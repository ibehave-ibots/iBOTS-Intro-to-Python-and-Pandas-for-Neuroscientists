{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  %pip install --upgrade numpy matplotlib pandas seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Experiment's Design\n",
    "\n",
    "In this set of exercises, we'll get our first look at the experiment we'll be analyzing in this course; curated data from the [Steinmetz et al, 2019](https://www.nature.com/articles/s41586-019-1787-x) paper.  \n",
    "\n",
    "Today's data is focused on three CSV files, each containing sessions from a different stretch of data collection.  They contain trial-level data from the experiment: \n",
    "  - `steinmetz_winter2016.csv`\n",
    "  - `steinmetz_summer2017.csv`\n",
    "  - `steinmetz_winter2017.csv`\n",
    "\n",
    "These exercises are meant to get practice in working with **Pandas Dataframes**, a tool that appears in a lot of Python data science analyses!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data and Get a Quick Description\n",
    "\n",
    "```python\n",
    "pd.read_csv()\n",
    "df.head(5), df[:5]\n",
    "df.tail(5), df[-5:]\n",
    "len(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercises\n",
    "\n",
    "Let's get a sense of what kind of data is in these files.  Load each of the datasets into a different variable name using the `pd.read_csv()` function, and answer the questions below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Load the Winter 2016 dataset and preview the first 3 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/final/steinmetz_winter2016.csv')\n",
    "df1[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Winter 2017 Dataset and preview the first 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./data/final/steinmetz_winter2017.csv')\n",
    "df2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Summer 2017 Dataset and preview the last 4 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('./data/final/steinmetz_summer2017.csv')\n",
    "df3[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of rows (i.e. the \"length\") of each of the three datasets. In this data, each row represents one trial.  Which file contained the most trials?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: N Trials, Winter 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N Trials, Winter 2017:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N Trials, Summer 2017:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Structure of a Dataset for the Purpose of Merging Them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-session data is easiest to analyze with when each session is organized the same way, and contains the same variables.  In a table (what the `pandas` library calls a `DataFrame`), that means all the datasets have the same columns and that they store the same kind of data. \n",
    "\n",
    "Useful code:\n",
    "  - **df.columns**\n",
    "  - **df.dtypes**\n",
    "  - **df.info()** \n",
    "\n",
    "**Exercises** \n",
    "\n",
    "Let's look in more detail at each of these tables' structures!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: What columns are in the Winter 2016 data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What columns are in the Winter 2017 data, and under data type (i.e. \"dtype\") is each column's data formatted as? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Summer 2017 data, let's get more `info`; in this case, the number of rows with non-missing data for each column, as well as much memory the dataset takes up on the computer.\n",
    "\n",
    "Is there any missing data in the Summer 2017 dataset?  And how many kilobytes does it take up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the Datasets\n",
    "\n",
    "Having three different variables that contain similar data makes it harder for us to analyze our data.  Let's concatenate the data into a single table to use for the rest of this analysis.  The following line of code is helpful here:\n",
    "\n",
    "```python\n",
    "df = pd.concat(             # The concat() function, from the Pandas package.\n",
    "    [dataset1, dataset2],   # A list of variables referencing DataFrmaes\n",
    "    ignore_index=True,      # Recalculate the row number labels.\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Concatenate the three tables into a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trials are in the entire dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we concatenate multiple dataframes the index values are also concatenated and therefore are not unique to each row any longer. To make index values unique again we can make use of the method `.reset_index()`. Let's do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the same columns still in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Categorical Data: Counting Sessions, Mice, and Trial Conditions\n",
    "\n",
    "In Python, the square brackets can be used to get data from a data collection.  In the case of Pandas Dataframes (which our table is an instance of), this lets us get the columns by name.\n",
    "\n",
    "```python\n",
    "df['column'].nunique()\n",
    "df['column'].unique()\n",
    "df['column'].value_counts().sort_index()\n",
    "df[['column1', 'column2']].value_counts().sort_index()  # note the double square brackets; these are needed when getting multiple columns at once.\n",
    "```\n",
    "\n",
    "Let's use these techniques to answer some questions about how the experiment was structured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sessions are in the entire dataset (i.e. how many unique values are there in the column \"session_id\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many mice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mouse'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the names of the mice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mouse'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the different contrast levels for the left stimulus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contrast_left'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different contrast levels are there for the left stimulus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contrast_left'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the different values in feedback_types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feedback_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the different values in response types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trials were considered \"active\" (i.e. the mouse was expected to be actively responding to the stimuli, vs just being passively shown stimuli at the end of a session)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['active_trials'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trials did each of the mice do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mouse'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trials were there for each value of `contrast_left`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contrast_left'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each trial contained two stimuli: one on the left of the mouse, and one on the right, each with their own contrast levels.  How many triasl were there for each combination of `contrast_left` and `contrast_right`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['contrast_left', 'contrast_right']].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Statics on Continuous Data: Measuring Response Time\n",
    "\n",
    "```python\n",
    "df['column'].min()\n",
    "df['column'].max()\n",
    "df['column'].mean()\n",
    "df['column'].median()\n",
    "df['column'].std()\n",
    "df[['column1', 'column2']].mean()   # it's possible to calculate on multiple columns at once\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the minimum response time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response_time'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the maximum response time across all the trials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response_time'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the mean response time?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response_time'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the median response time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response_time'].median()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra**: It's possible to calculate multiple aggregation statistics at the same time, as well, using the `df.agg()` method and giving it a list of statistic functions to call on the data, for example from the numpy (`np`) package:\n",
    "\n",
    "```python\n",
    "df[['column1', 'column2']].agg([np.mean, np.min, np.max])\n",
    "```\n",
    "\n",
    "If you like, try out this pattern by calculating the min, max, mean, and median at the same time on the response times and the reaction times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['response_time', 'reaction_time']].agg([np.mean, np.median, np.min, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Description: Calculating Statistics of Across Categorical Data\n",
    "\n",
    "Perhaps the most useful pattern in all of data science is the `group-by` pattern; it lets you compute a statistic on different groups of data, essentially building a mini analysis pipeline in a single line of code!  \n",
    "\n",
    "Here is the pattern, broken down into its individual steps:\n",
    "\n",
    "\n",
    "```python\n",
    "(\n",
    "df                     # 1. Choose a dataset\n",
    ".groupby('column1')    # 2. Split the Data into sub-datasets, based on values in column1\n",
    "['column2']            # 3. Get column2 in each of those sub-datasets\n",
    ".mean()                # 4. Calculate the mean of column2 for each sub-dataset\n",
    ")\n",
    "```\n",
    "\n",
    " Below are some examples of the pattern:\n",
    "\n",
    "```python\n",
    "df.groupby('column1')['column2'].size()\n",
    "df.groupby('column1')['column2'].size().sort_index()\n",
    "df.groupby('column1')['column2'].size().mean()\n",
    "df.groupby('column1')['column2'].median()\n",
    "df.groupby('column1')['column2'].min()\n",
    "df.groupby('column1')['column2'].max()\n",
    "df.groupby(['column1', 'column2'])['column3'].mean()\n",
    "df.groupby(['column1', 'column2'])['column3'].median()\n",
    "df.groupby(['column1', 'column2'])['column3'].median().reset_index()\n",
    "df.groupby('column1')['column2'].plot.bar()  # bar plot\n",
    "df.groupby('column1')['column2'].plot.barh() # horizontal bar plot\n",
    "df.groupby('column1')['column2'].size().plot.line()  # line plot\n",
    "```\n",
    "\n",
    "\n",
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trials did each mouse perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('mouse').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trials were there of each contrast_left level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('contrast_left').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the mean response time for each mouse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('mouse')['response_time'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the mean number of trials in each session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('session_id').size().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the minimum number of trials in a session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('session_id').size().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sessions did each mouse do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('mouse')['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trials were their of each combination of contrast_left and contrast_right levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['contrast_left', 'contrast_right']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a bar plot showing how many trials there were for each contrast_right level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('contrast_right').size().plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a horizontal bar plot showing how many sessions each mouse did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('mouse')['session_id'].nunique().plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a line plot showing how many trials there were for each contrast_left level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('contrast_left').size().plot.line();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Experimental Design using Some Useful Plotting Recipes\n",
    "\n",
    "We'll be using the Seaborn package a lot in this course, because it makes it straightforward to describe how a plot should be made using the names of the columns in the dataset.  Let's try out a few using the following patterns:\n",
    "\n",
    "```python\n",
    "sns.countplot(df['column1']);\n",
    "sns.histplot(df['column1']);\n",
    "sns.kdeplot(df['column1']);\n",
    "sns.heatmap(df.groupby(['column1', 'column2'])['column3'].size().unstack())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some plots of the data using Seaborn (`sns`)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: How many trials were in each session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, y=\"session_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trials did each mouse do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, y=\"mouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a histogram of the response times in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='response_time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a kernel density estimate (kind of a smoothed histogram) of the response times in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df, x=\"response_time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is a little more complex: Using `groupby`, `size()`, and `unstack`, make a heatmap of showing number of contrast_left and contrast_right trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby(['contrast_left', 'contrast_right']).size().unstack());"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
